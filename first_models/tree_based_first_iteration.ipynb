{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = [\n",
    "    {\n",
    "        \"min_samples_split\": [50, 100],\n",
    "        \"max_depth\": [20, 30, 40],\n",
    "        \"n_estimators\": [100, 200]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Let's also try some CV\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "# now you can import normally from model_selection\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_encoded[features], df_encoded[target], train_size = .9)\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=42)\n",
    "\n",
    "search = HalvingGridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    scoring='precision',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_encoded[features], df_encoded[target], train_size = .9)\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3)\n",
    "\n",
    "# search = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "#                       param_grid=param_grid, \n",
    "#                       scoring='accuracy', \n",
    "#                       cv=cv,\n",
    "#                       n_jobs=-1)\n",
    "# search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(search.cv_results_)\n",
    "results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
    "results_df = results_df.set_index(\n",
    "    results_df[\"params\"].apply(lambda x: \"_\".join(str(val) for val in x.values()))\n",
    ").rename_axis(\"kernel\")\n",
    "results_df[[\"params\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = search.best_estimator_.predict(X_test)\n",
    "print(y_test.shape)\n",
    "print(accuracy_score(yhat_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df[target] == 1])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, yhat_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = search.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, yhat_train)\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['yes', 'no'], yticklabels=['yes', 'no'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am sure that more estimators is generating better results.\n",
    "\n",
    "rfmodel = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=50,\n",
    "    min_samples_split=50,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ").fit(df_encoded[features], df_encoded[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "yhat_rf = rfmodel.predict(df_encoded[features])\n",
    "cm = confusion_matrix(df_encoded[target], yhat_rf)\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['yes', 'no'], yticklabels=['yes', 'no'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "xgb_model.fit(df_encoded[features], df_encoded[target])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
