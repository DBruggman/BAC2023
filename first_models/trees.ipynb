{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First iteration of tree-based models.\n",
    "\n",
    "The hyperparameter optization process will be the following:\n",
    "1. Train with default hyperaparameters.\n",
    "2. Identify bias and variance.\n",
    "3. Choose first range for hyperparameters based on results.\n",
    "4. Train n models using HalvingRandomSearchCV from scikit learn.\n",
    "5. Pick the regions of the hyperparameter space that yield the best results.\n",
    "6. Centre the hyperparameter search on those regions and iterate.\n",
    "\n",
    "The scoring will consist in:\n",
    "1. Numerical scores for the testing subset: recall, precision, roc_auc, f1.\n",
    "2. Numerical scores for the whole data: recall, precision, roc_auc, f1.\n",
    "2. Visualization of the ROC curve for the whole data.\n",
    "4. Confusion matrix for the whole data.\n",
    "\n",
    "In this way we can see if each model over/underfits, comparing the test and total scores. Also, the ROC curve and the confusion matrix will show how each model is performing in the whole dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# For random number generation\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv # Allow importing the experimental HalvingGridSearchCV\n",
    "\n",
    "# Metrics and auxiliar libraries from sklearn.\n",
    "from sklearn.model_selection import train_test_split, HalvingRandomSearchCV, RepeatedStratifiedKFold, HalvingGridSearchCV\n",
    "\n",
    "# Some auxiliary functions for scoring.\n",
    "import scoring_utils\n",
    "\n",
    "#DEV\n",
    "import importlib as imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataframe cleaned and encoded during the feature importance process.\n",
    "df_encoded = pd.read_csv('../data/df_encoded_interest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Default'\n",
    "features_encoded = [feature for feature in df_encoded.columns if feature not in target]\n",
    "# Our target and features are the same that we employed during the importance analysis.\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Features: {features_encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This split will be used in every model, so that they are scored against the same subset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_encoded[features_encoded], df_encoded[target], train_size = .9)\n",
    "# Complete datasets\n",
    "X_total = df_encoded[features_encoded]\n",
    "y_total = df_encoded[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default check to identify bias/variance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "default_tree = DecisionTreeClassifier()\n",
    "default_tree.fit(X_train, y_train)\n",
    "\n",
    "yhat_train = default_tree.predict(X_train)\n",
    "yhat_test = default_tree.predict(X_test)\n",
    "\n",
    "default_tree_score = pd.concat((\n",
    "    scoring_utils.get_metrics(y_train, yhat_train, \"Default Tree Train\"),\n",
    "    scoring_utils.get_metrics(y_test, yhat_test, \"Default Tree Test\")\n",
    "    ))\n",
    "\n",
    "default_tree_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tree.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does overfit! Let's decrease the variance by tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grid of parameters for a single tree\n",
    "param_grid = [\n",
    "    {\n",
    "        \"min_samples_split\": randint(100, 200),\n",
    "        \"max_depth\": randint(14, 18)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Cross validation in 3 folds for our grid search parameter selection.\n",
    "# It must be consistent across the folds, so the random state has to be fixed.\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=9)\n",
    "\n",
    "single_tree_search = HalvingRandomSearchCV(\n",
    "    estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
    "    param_distributions=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    n_candidates=1000\n",
    ")\n",
    "\n",
    "single_tree_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_best_kernels(single_tree_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_encoded[df_encoded[target] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights = [.1, .15, .2, .25, .3]\n",
    "\n",
    "for weight in weights:\n",
    "    print(f\"\\nTraining for weight: {weight}...\")\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth= 15,\n",
    "        min_samples_split=130,\n",
    "        class_weight={0: weight, 1:(1-weight)}\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    yhat_test = model.predict(X_test)\n",
    "    yhat_train = model.predict(X_train)\n",
    "    yhat_total = model.predict(X_total)\n",
    "\n",
    "    score = pd.concat([\n",
    "        scoring_utils.get_metrics(y_train, yhat_train, \"Train\"),\n",
    "        scoring_utils.get_metrics(y_test, yhat_test, \"Test\"),\n",
    "        scoring_utils.get_metrics(y_total, yhat_total, \"Total\")\n",
    "    ])\n",
    "\n",
    "    print(score)\n",
    "\n",
    "    print(f\"We obtained a profit of ${scoring_utils.get_profit(X_total, y_total, yhat_total):,.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the best estimator to obtain test and overall scores \n",
    "single_tree_model = single_tree_search.best_estimator_\n",
    "\n",
    "yhat_test = single_tree_model.predict(X_test)\n",
    "yhat_total = single_tree_model.predict(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree_test_score = scoring_utils.get_metrics(y_test, yhat_test, \"Single Tree Test\")\n",
    "single_tree_total_score = scoring_utils.get_metrics(y_total, yhat_total, \"Single Tree Total\")\n",
    "\n",
    "single_tree_score = pd.concat((single_tree_test_score, single_tree_total_score))\n",
    "single_tree_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We obtained a profit of ${scoring_utils.get_profit(X_total, y_total, yhat_total):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_roc_plot(y_total, yhat_total, \"Single Tree Whole Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_confusion_matrix(y_total, yhat_total, \"Single Tree Whole Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default check to identify bias/variance\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "default_bagging = BaggingClassifier(DecisionTreeClassifier(), n_jobs=-1)\n",
    "default_bagging.fit(X_train, y_train)\n",
    "\n",
    "yhat_train = default_bagging.predict(X_train)\n",
    "yhat_test = default_bagging.predict(X_test)\n",
    "\n",
    "default_bagging_score = pd.concat((\n",
    "    scoring_utils.get_metrics(y_train, yhat_train, \"Default Bagging Train\"),\n",
    "    scoring_utils.get_metrics(y_test, yhat_test, \"Default Bagging Test\")\n",
    "    ))\n",
    "\n",
    "default_bagging_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_bagging.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grid of parameters for a bagging model\n",
    "param_grid = [\n",
    "    {\n",
    "        \"max_samples\": [.8, .9, 1.0]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Cross validation in 3 folds for our grid search parameter selection.\n",
    "# It must be consistent across the folds, so the random state has to be fixed.\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=9)\n",
    "\n",
    "bagging_search = HalvingGridSearchCV(\n",
    "    estimator=BaggingClassifier(n_estimators=10, estimator=single_tree_model),\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "bagging_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_best_kernels(bagging_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_model = bagging_search.best_estimator_\n",
    "\n",
    "yhat_test = bagging_model.predict(X_test)\n",
    "yhat_total = bagging_model.predict(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_test_score = scoring_utils.get_metrics(y_test, yhat_test, \"Bagging Test\")\n",
    "bagging_total_score = scoring_utils.get_metrics(y_total, yhat_total, \"Bagging Total\")\n",
    "\n",
    "bagging_score = pd.concat((bagging_test_score, bagging_total_score, single_tree_score))\n",
    "bagging_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We obtained a profit of ${scoring_utils.get_profit(X_total, y_total, yhat_total):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_roc_plot(y_total, yhat_total, \"Bagging Whole Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_confusion_matrix(y_total, yhat_total, \"Bagging Whole Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default to check bias/variance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "default_forest = RandomForestClassifier(n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "yhat_train = default_forest.predict(X_train)\n",
    "yhat_test = default_forest.predict(X_test)\n",
    "\n",
    "default_forest_score = pd.concat((\n",
    "    scoring_utils.get_metrics(y_train, yhat_train, 'Default Forest Train'),\n",
    "    scoring_utils.get_metrics(y_test, yhat_test, 'Default Forest Test')\n",
    "))\n",
    "\n",
    "default_forest_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_forest.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'max_depth': 14, 'min_samples_split': 109} # One of my best trees!!!!!\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [50, 100, 150], # This has a smaller effect, but 100 seems to work out fine.\n",
    "    'min_samples_split': [10, 100, 1000] # This should be around 100\n",
    "}\n",
    "\n",
    "# Cross validation in 3 folds for our grid search parameter selection.\n",
    "# It must be consistent across the folds, so the random state has to be fixed.\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=9)\n",
    "\n",
    "random_forest_search = HalvingGridSearchCV(\n",
    "    estimator=RandomForestClassifier(n_estimators=50, max_features=1.0, class_weight='balanced'),\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_forest_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_best_kernels(random_forest_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = random_forest_search.best_estimator_\n",
    "\n",
    "yhat_test = random_forest.predict(X_test)\n",
    "yhat_total = random_forest.predict(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_test_score = scoring_utils.get_metrics(y_test, yhat_test, \"Random Forest Test\")\n",
    "forest_total_score = scoring_utils.get_metrics(y_total, yhat_total, \"Random Forest Total\")\n",
    "\n",
    "forest_score = pd.concat((forest_test_score, forest_total_score, bagging_score))\n",
    "forest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We obtained a profit of ${scoring_utils.get_profit(X_total, y_total, yhat_total):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_roc_plot(y_total, yhat_total, \"Forest Whole Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_confusion_matrix(y_total, yhat_total, \"Random Forest Whole Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=100,\n",
    " verbosity=2,\n",
    " max_depth=11,\n",
    " min_child_weight=10,\n",
    " gamma=0.1,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " scale_pos_weight=3.3,\n",
    " seed=27)\n",
    "\n",
    "xgb_param = xgbmodel.get_xgb_params()\n",
    "xgtrain = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=xgbmodel.get_params()['n_estimators'], nfold=5,\n",
    "metrics='auc', early_stopping_rounds=50)\n",
    "xgbmodel.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "xgbmodel.fit(X_train, y_train, eval_metric='auc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = xgbmodel.predict(X_train)\n",
    "yhat_test = xgbmodel.predict(X_test)\n",
    "\n",
    "cv_boost_score = pd.concat((\n",
    "    scoring_utils.get_metrics(y_train, yhat_train, 'CV Boosting Train'),\n",
    "    scoring_utils.get_metrics(y_test, yhat_test, 'CV Boosting Test')\n",
    "))\n",
    "\n",
    "cv_boost_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_total = xgbmodel.predict(X_total)\n",
    "scoring_utils.get_confusion_matrix(y_total, yhat_total, 'CV Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We obtained a profit of ${scoring_utils.get_profit(X_total, y_total, yhat_total):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The maximum is ${scoring_utils.get_profit(X_total, y_total, y_total):,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This fuckers works worse. Check if there's time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "weights = [3.3, 3.5, 3.7, 3.9]\n",
    "\n",
    "for weight in weights:\n",
    "    print(f\"\\nTraining for weight: {weight}...\")\n",
    "    model = xgb.XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=100,\n",
    "        verbosity=2,\n",
    "        max_depth=11,\n",
    "        min_child_weight=10,\n",
    "        gamma=0.1,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        seed=27,\n",
    "        scale_pos_weight=weight)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    yhat_test = model.predict(X_test)\n",
    "    yhat_train = model.predict(X_train)\n",
    "    yhat_total = model.predict(X_total)\n",
    "\n",
    "    score = pd.concat([\n",
    "        scoring_utils.get_metrics(y_train, yhat_train, \"Train\"),\n",
    "        scoring_utils.get_metrics(y_test, yhat_test, \"Test\"),\n",
    "        scoring_utils.get_metrics(y_total, yhat_total, \"Total\")\n",
    "    ])\n",
    "\n",
    "    print(score)\n",
    "\n",
    "    print(f\"We obtained a profit of ${scoring_utils.get_profit(X_total, y_total, yhat_total):,.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = [{\n",
    "    'scale_pos_weight': [3, 4, 4.5, 5, 5.5, 6]\n",
    "}]\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=12)\n",
    "\n",
    "xgbsearch = HalvingGridSearchCV(\n",
    "    xgb.XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=100,\n",
    "        verbosity=2,\n",
    "        max_depth=11,\n",
    "        min_child_weight=10,\n",
    "        gamma=0.1,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        seed=27),\n",
    "    param_grid=param_grid,\n",
    "    verbose=1,\n",
    "    cv=cv,\n",
    "    scoring='recall'\n",
    ")\n",
    "\n",
    "xgbsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_best_kernels(xgbsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel = xgbsearch.best_estimator_\n",
    "\n",
    "yhat_test = xgbmodel.predict(X_test)\n",
    "yhat_total = xgbmodel.predict(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_score = scoring_utils.get_metrics(y_test, yhat_test, \"XGB Test\")\n",
    "xgb_total_score = scoring_utils.get_metrics(y_total, yhat_total, \"XGB Total\")\n",
    "\n",
    "xgb_score = pd.concat((xgb_test_score, xgb_total_score))\n",
    "xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_confusion_matrix(y_total, yhat_total, \"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We obtained a profit of ${scoring_utils.get_profit(X_total, y_total, yhat_total):,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb1 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=100,\n",
    " verbosity=2,\n",
    " max_depth=11,\n",
    " min_child_weight=10,\n",
    " gamma=0.1,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " scale_pos_weight=5,\n",
    " seed=27)\n",
    "modelfit(xgb1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'max_depth': hp.quniform(\"max_depth\", 9, 12, 1),\n",
    "        'gamma': hp.uniform ('gamma', 0, 1.5),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 20, 1),\n",
    "        'scale_pos_weight': 5,\n",
    "        'subsample': .9\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb1 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=100,\n",
    " verbosity=2,\n",
    " max_depth=11,\n",
    " min_child_weight=10,\n",
    " gamma=0.1,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " scale_pos_weight=5,\n",
    " seed=27)\n",
    "modelfit(xgb1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "        learning_rate= 0.1, \n",
    "        max_depth = 11,\n",
    "        gamma = 0.1,           \n",
    "        colsample_bytree= .8,\n",
    "        min_child_weight= 10,\n",
    "        scale_pos_weight= 5,\n",
    "        subsample= .9,\n",
    "        n_estimators = 100, \n",
    "        eval_metric='recall',\n",
    "        early_stopping_rounds=10 ,\n",
    "        verbosity=2,\n",
    "        objective= 'binary:logistic'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(space):\n",
    "    model = XGBClassifier(\n",
    "        learning_rate= space['learning_rate'], \n",
    "        max_depth = int(space['max_depth']),\n",
    "        gamma = space['gamma'],           \n",
    "        reg_alpha = int(space['reg_alpha']),\n",
    "        reg_lambda = space['reg_lambda'],\n",
    "        colsample_bytree=space['colsample_bytree'],\n",
    "        min_child_weight=space['min_child_weight'],\n",
    "        scale_pos_weight= 5,\n",
    "        subsample= .9,\n",
    "        n_estimators = 100, \n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=10 \n",
    "    )\n",
    "\n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "            eval_set=evaluation,\n",
    "            verbose=True)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    recall = f1_score(y_test, pred)\n",
    "    print (\"SCORE:\", recall)\n",
    "    #change the metric if you like\n",
    "    return {'loss': -recall, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_profit(X_total, y_total, y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    colsample_bytree=best['colsample_bytree'],\n",
    "    gamma=best['gamma'],\n",
    "    learning_rate=best['learning_rate'],\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_child_weight=best['min_child_weight'],\n",
    "    reg_alpha=best['reg_alpha'],\n",
    "    reg_lambda=best['reg_lambda'],\n",
    "    scale_pos_weight= 5,\n",
    "    subsample= .9,\n",
    "    n_estimators = 100, \n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "old_version = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=100,\n",
    " verbosity=2,\n",
    " max_depth=11,\n",
    " min_child_weight=10,\n",
    " gamma=0.1,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " scale_pos_weight=5,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "trial.fit(X_train, y_train,\n",
    "            eval_set=evaluation,\n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = trial.predict(X_test)\n",
    "yhat_total = trial.predict(X_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_metrics(y_test, yhat_test, \"Trial Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_metrics(y_total, yhat_total, \"Trial Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_confusion_matrix(y_total, yhat_total, \"Old model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_profit(X_total, y_total, yhat_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
