{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First iteration of tree-based models.\n",
    "\n",
    "The hyperparameter optization process will be the following:\n",
    "1. Choose first range for hyperparameters.\n",
    "2. Train n models using HalvingRandomSearchCV from scikit learn.\n",
    "3. Pick the regions of the hyperparameter space that yield the best results.\n",
    "4. Centre the hyperparameter search on those regions and iterate.\n",
    "\n",
    "The scoring will consist in:\n",
    "1. Numerical scores for the testing subset: recall, precision, roc_auc, f1.\n",
    "2. Numerical scores for the whole data: recall, precision, roc_auc, f1.\n",
    "2. Visualization of the ROC curve for the whole data.\n",
    "4. Confusion matrix for the whole data.\n",
    "\n",
    "In this way we can see if each model over/underfits, comparing the test and total scores. Also, the ROC curve and the confusion matrix will show how each model is performing in the whole dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# For random number generation\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv # Allow importing the experimental HalvingGridSearchCV\n",
    "\n",
    "# Metrics and auxiliar libraries from sklearn.\n",
    "from sklearn.model_selection import train_test_split, HalvingRandomSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "# Some auxiliary functions for scoring.\n",
    "import scoring_utils\n",
    "\n",
    "#DEV\n",
    "import importlib as imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataframe cleaned and encoded during the feature importance process.\n",
    "df_encoded = pd.read_csv('../data/df_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Default'\n",
    "features_encoded = [feature for feature in df_encoded.columns if feature not in target]\n",
    "# Our target and features are the same that we employed during the importance analysis.\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Features: {features_encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This split will be used in every model, so that they are scored against the same subset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_encoded[features_encoded], df_encoded[target], train_size = .9)\n",
    "# Complete datasets\n",
    "X_total = df_encoded[features_encoded]\n",
    "y_total = df_encoded[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Grid of parameters for a single tree\n",
    "param_grid = [\n",
    "    {\n",
    "        \"min_samples_split\": randint(155, 160),\n",
    "        \"max_depth\": randint(16, 20),\n",
    "        \"min_samples_leaf\": randint(50, 150),\n",
    "        \"max_leaf_nodes\": randint(1300, 2000)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Cross validation in 3 folds for our grid search parameter selection.\n",
    "# It must be consistent across the folds, so the random state has to be fixed.\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=9)\n",
    "\n",
    "single_tree_search = HalvingRandomSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_distributions=param_grid,\n",
    "    scoring='recall',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    n_candidates=1000\n",
    ")\n",
    "\n",
    "single_tree_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_best_kernels(single_tree_search.cv_results_).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the best estimator to obtain test and overall scores \n",
    "single_tree_model = single_tree_search.best_estimator_\n",
    "\n",
    "yhat_test = single_tree_model.predict(X_test)\n",
    "yhat_total = single_tree_model.predict(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree_test_score = scoring_utils.get_metrics(yhat_test, y_test, \"Single Tree Test\")\n",
    "single_tree_total_score = scoring_utils.get_metrics(yhat_total, y_total, \"Single Tree Total\")\n",
    "\n",
    "single_tree_score = pd.concat((single_tree_test_score, single_tree_total_score))\n",
    "single_tree_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_baseline = pd.read_csv('../data/baseline_predict.csv')\n",
    "scoring_utils.get_metrics(yhat_baseline, y_total, \"Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_roc_plot(yhat_test, y_test, \"Single Tree Whole Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_confusion_matrix(y_total, yhat_total, \"Single Tree Whole Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Grid of parameters for a bagging classifier\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         \"estimator__min_samples_split\": randint(155, 160),\n",
    "#         \"estimator__max_depth\": randint(16, 20),\n",
    "#         \"estimator__min_samples_leaf\": randint(50, 150),\n",
    "#         \"n_estimators\": randint(220, 320)\n",
    "#     }\n",
    "#] \n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500, 600, 700, 800],\n",
    "    'max_features': [0.90, 0.92, 0.95, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False],\n",
    "}\n",
    "\n",
    "# Cross validation in 3 folds for our grid search parameter selection.\n",
    "# It must be consistent across the folds, so the random state has to be fixed.\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=9)\n",
    "\n",
    "bagging_search = HalvingRandomSearchCV(\n",
    "    estimator=BaggingClassifier(DecisionTreeClassifier()),\n",
    "    param_distributions=param_grid,\n",
    "    scoring='recall',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    n_candidates=50\n",
    ")\n",
    "\n",
    "bagging_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_best_kernels(bagging_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the best estimator to obtain test and overall scores \n",
    "bagging_model = bagging_search.best_estimator_\n",
    "\n",
    "yhat_test = bagging_model.predict(X_test)\n",
    "yhat_total = bagging_model.predict(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_test_score = scoring_utils.get_metrics(yhat_test, y_test, \"Bagging Test\")\n",
    "bagging_total_score = scoring_utils.get_metrics(yhat_total, y_total, \"Bagging Total\")\n",
    "\n",
    "bagging_score = pd.concat((bagging_test_score, bagging_total_score))\n",
    "bagging_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_baseline = pd.read_csv('../data/baseline_predict.csv')\n",
    "scoring_utils.get_metrics(yhat_baseline, y_total, \"Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_roc_plot(yhat_test, y_test, \"Bagging Whole Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_utils.get_confusion_matrix(y_total, yhat_total, \"Bagging Whole Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
