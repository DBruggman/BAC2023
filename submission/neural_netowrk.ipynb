{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Metrics and auxiliar libraries from sklearn.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Some auxiliary functions for scoring and tuning\n",
    "import scoring_utils, tuning_utils\n",
    "\n",
    "#DEV\n",
    "import importlib as imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataframe cleaned during the feature importance process.\n",
    "df = pd.read_csv('../data/data_clean.csv')\n",
    "target = 'Default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Add UrbanRural one-hot encoded version diretly to the dataframe. That encoding is straighforward.\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_urban_rural = encoder.fit_transform(df[['UrbanRural']])\n",
    "encoded_urban_rural = pd.DataFrame(encoded_urban_rural, columns=encoder.get_feature_names_out(['UrbanRural']))\n",
    "\n",
    "encoded_urban_rural.index = df.index\n",
    "\n",
    "# Concatenating the encoded DataFrame with the original DataFrame\n",
    "df = pd.concat([df, encoded_urban_rural], axis=1)\n",
    "\n",
    "all_features = [feature for feature in df.columns if feature not in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add count encoded features\n",
    "experimental_features = ['City', 'State', 'Bank', 'ApprovalFY', 'NAICS_i', 'FranchiseCode']\n",
    "features = [f for f in all_features if f not in experimental_features]\n",
    "# Count encoding\n",
    "count_encoded_features = ['City', 'Bank', 'State']\n",
    "features_count_encoding = features + count_encoded_features\n",
    "\n",
    "for feature in count_encoded_features:\n",
    "    df[feature + 'Loans'] = df.groupby(feature)[feature].transform('count')\n",
    "    df[feature + 'Loans'].fillna(0, inplace=True)\n",
    "\n",
    "    features_count_encoding.remove(feature)\n",
    "    features_count_encoding.append(feature+'Loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = df[features_count_encoding]\n",
    "y_total = df[target]\n",
    "\n",
    "X_train, X_, y_train, y_ = train_test_split(X_total, y_total, train_size=.8)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_, y_, train_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_cv_scaled = scaler.transform(X_cv)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_total = scaler.transform(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>isNewBusiness</th>\n",
       "      <th>isFranchise</th>\n",
       "      <th>SBARatio</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>UrbanRural_0</th>\n",
       "      <th>UrbanRural_1</th>\n",
       "      <th>UrbanRural_2</th>\n",
       "      <th>CityLoans</th>\n",
       "      <th>BankLoans</th>\n",
       "      <th>StateLoans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "      <td>870514.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000390</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000472</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>-0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.999668</td>\n",
       "      <td>1.007419</td>\n",
       "      <td>1.007053</td>\n",
       "      <td>1.006260</td>\n",
       "      <td>0.999677</td>\n",
       "      <td>1.000019</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.000333</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>1.001165</td>\n",
       "      <td>1.000007</td>\n",
       "      <td>1.000288</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>1.000386</td>\n",
       "      <td>1.000287</td>\n",
       "      <td>0.999605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.408263</td>\n",
       "      <td>-0.154891</td>\n",
       "      <td>-0.035737</td>\n",
       "      <td>-0.045600</td>\n",
       "      <td>-1.164794</td>\n",
       "      <td>-0.545535</td>\n",
       "      <td>-0.376277</td>\n",
       "      <td>-0.682837</td>\n",
       "      <td>-0.659975</td>\n",
       "      <td>-0.627502</td>\n",
       "      <td>-0.248748</td>\n",
       "      <td>-3.945579</td>\n",
       "      <td>-1.764203</td>\n",
       "      <td>-0.754264</td>\n",
       "      <td>-1.040714</td>\n",
       "      <td>-0.364785</td>\n",
       "      <td>-0.531032</td>\n",
       "      <td>-0.774806</td>\n",
       "      <td>-1.037924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.650724</td>\n",
       "      <td>-0.127879</td>\n",
       "      <td>-0.035737</td>\n",
       "      <td>-0.045600</td>\n",
       "      <td>-1.164794</td>\n",
       "      <td>-0.545535</td>\n",
       "      <td>-0.376277</td>\n",
       "      <td>-0.563259</td>\n",
       "      <td>-0.564257</td>\n",
       "      <td>-0.627502</td>\n",
       "      <td>-0.248748</td>\n",
       "      <td>-1.221454</td>\n",
       "      <td>-0.968518</td>\n",
       "      <td>-0.754264</td>\n",
       "      <td>-1.040714</td>\n",
       "      <td>-0.364785</td>\n",
       "      <td>-0.495604</td>\n",
       "      <td>-0.753909</td>\n",
       "      <td>-0.713635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.347708</td>\n",
       "      <td>-0.100867</td>\n",
       "      <td>-0.035737</td>\n",
       "      <td>-0.041415</td>\n",
       "      <td>0.378339</td>\n",
       "      <td>-0.545535</td>\n",
       "      <td>-0.376277</td>\n",
       "      <td>-0.355755</td>\n",
       "      <td>-0.383527</td>\n",
       "      <td>-0.627502</td>\n",
       "      <td>-0.248748</td>\n",
       "      <td>0.221837</td>\n",
       "      <td>0.257020</td>\n",
       "      <td>-0.754264</td>\n",
       "      <td>0.960879</td>\n",
       "      <td>-0.364785</td>\n",
       "      <td>-0.394311</td>\n",
       "      <td>-0.535774</td>\n",
       "      <td>-0.454755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.106816</td>\n",
       "      <td>-0.019830</td>\n",
       "      <td>-0.031540</td>\n",
       "      <td>-0.028859</td>\n",
       "      <td>0.378339</td>\n",
       "      <td>-0.545535</td>\n",
       "      <td>-0.376277</td>\n",
       "      <td>0.122557</td>\n",
       "      <td>0.111457</td>\n",
       "      <td>1.593621</td>\n",
       "      <td>-0.248748</td>\n",
       "      <td>0.799154</td>\n",
       "      <td>0.631998</td>\n",
       "      <td>1.325796</td>\n",
       "      <td>0.960879</td>\n",
       "      <td>-0.364785</td>\n",
       "      <td>-0.035542</td>\n",
       "      <td>0.521853</td>\n",
       "      <td>0.377974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.775737</td>\n",
       "      <td>134.893409</td>\n",
       "      <td>36.894968</td>\n",
       "      <td>39.715138</td>\n",
       "      <td>1.921471</td>\n",
       "      <td>1.833062</td>\n",
       "      <td>2.657617</td>\n",
       "      <td>16.898667</td>\n",
       "      <td>19.006093</td>\n",
       "      <td>1.593621</td>\n",
       "      <td>4.020129</td>\n",
       "      <td>1.665128</td>\n",
       "      <td>6.938032</td>\n",
       "      <td>1.325796</td>\n",
       "      <td>0.960879</td>\n",
       "      <td>2.741338</td>\n",
       "      <td>5.016666</td>\n",
       "      <td>2.243311</td>\n",
       "      <td>2.173594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Term          NoEmp      CreateJob    RetainedJob  \\\n",
       "count  870514.000000  870514.000000  870514.000000  870514.000000   \n",
       "mean       -0.000390       0.000156       0.000406       0.000309   \n",
       "std         0.999668       1.007419       1.007053       1.006260   \n",
       "min        -1.408263      -0.154891      -0.035737      -0.045600   \n",
       "25%        -0.650724      -0.127879      -0.035737      -0.045600   \n",
       "50%        -0.347708      -0.100867      -0.035737      -0.041415   \n",
       "75%         0.106816      -0.019830      -0.031540      -0.028859   \n",
       "max         5.775737     134.893409      36.894968      39.715138   \n",
       "\n",
       "          UrbanRural      RevLineCr         LowDoc         GrAppv  \\\n",
       "count  870514.000000  870514.000000  870514.000000  870514.000000   \n",
       "mean        0.000087       0.000028      -0.000349      -0.000151   \n",
       "std         0.999677       1.000019       0.999603       0.999924   \n",
       "min        -1.164794      -0.545535      -0.376277      -0.682837   \n",
       "25%        -1.164794      -0.545535      -0.376277      -0.563259   \n",
       "50%         0.378339      -0.545535      -0.376277      -0.355755   \n",
       "75%         0.378339      -0.545535      -0.376277       0.122557   \n",
       "max         1.921471       1.833062       2.657617      16.898667   \n",
       "\n",
       "            SBA_Appv  isNewBusiness    isFranchise       SBARatio  \\\n",
       "count  870514.000000  870514.000000  870514.000000  870514.000000   \n",
       "mean       -0.000105      -0.000472       0.000618      -0.000278   \n",
       "std         1.000333       0.999773       1.001165       1.000007   \n",
       "min        -0.659975      -0.627502      -0.248748      -3.945579   \n",
       "25%        -0.564257      -0.627502      -0.248748      -1.221454   \n",
       "50%        -0.383527      -0.627502      -0.248748       0.221837   \n",
       "75%         0.111457       1.593621      -0.248748       0.799154   \n",
       "max        19.006093       1.593621       4.020129       1.665128   \n",
       "\n",
       "        InterestRate   UrbanRural_0   UrbanRural_1   UrbanRural_2  \\\n",
       "count  870514.000000  870514.000000  870514.000000  870514.000000   \n",
       "mean       -0.000084      -0.000369       0.000599      -0.000377   \n",
       "std         1.000288       0.999895       0.999976       0.999552   \n",
       "min        -1.764203      -0.754264      -1.040714      -0.364785   \n",
       "25%        -0.968518      -0.754264      -1.040714      -0.364785   \n",
       "50%         0.257020      -0.754264       0.960879      -0.364785   \n",
       "75%         0.631998       1.325796       0.960879      -0.364785   \n",
       "max         6.938032       1.325796       0.960879       2.741338   \n",
       "\n",
       "           CityLoans      BankLoans     StateLoans  \n",
       "count  870514.000000  870514.000000  870514.000000  \n",
       "mean       -0.000368       0.000213      -0.000557  \n",
       "std         1.000386       1.000287       0.999605  \n",
       "min        -0.531032      -0.774806      -1.037924  \n",
       "25%        -0.495604      -0.753909      -0.713635  \n",
       "50%        -0.394311      -0.535774      -0.454755  \n",
       "75%        -0.035542       0.521853       0.377974  \n",
       "max         5.016666       2.243311       2.173594  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_total, columns=features_count_encoding).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features have been succesfully scaled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating neural network of size [10]\n",
      "Creating neural network of size [16, 5]\n",
      "Creating neural network of size [32, 10, 20]\n",
      "Creating neural network of size [10, 20, 30, 10]\n",
      "Creating neural network of size [128, 64, 32, 64, 16, 4]\n",
      "Creating neural network of size [16, 64, 256, 1024, 512, 128, 32, 4]\n",
      "Creating neural network of size [190, 153, 120, 91, 66, 45, 28, 15, 6]\n"
     ]
    }
   ],
   "source": [
    "neural_sizes = [\n",
    "    [10],\n",
    "    [16, 5],\n",
    "    [32, 10, 20],\n",
    "    [10, 20, 30, 10],\n",
    "    [128, 64, 32, 64, 16, 4],\n",
    "    [16, 64, 256, 1024, 512, 128, 32, 4],\n",
    "    [190, 153, 120, 91, 66, 45, 28, 15, 6]\n",
    "]\n",
    "\n",
    "models = []\n",
    "\n",
    "for size in neural_sizes:\n",
    "    print(f\"Creating neural network of size {size}\")\n",
    "    model_name = '_'.join(map(str, size))\n",
    "    layers = []\n",
    "    #input = tf.keras.layers.Input((1,))\n",
    "    #layers.append(input)\n",
    "    for layer in size:\n",
    "        dense = tf.keras.layers.Dense(activation=\"relu\", units=layer)\n",
    "        layers.append(dense)\n",
    "    output = tf.keras.layers.Dense(activation=\"sigmoid\", units=1)\n",
    "    layers.append(output)\n",
    "\n",
    "    model = tf.keras.Sequential(layers, name=model_name)\n",
    "    #print(f\"Params: {model.count_params()}\")\n",
    "    models.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21763/21763 - 9s - loss: 0.3508 - 9s/epoch - 405us/step\n",
      "Epoch 2/10\n",
      "21763/21763 - 9s - loss: 0.3513 - 9s/epoch - 404us/step\n",
      "Epoch 3/10\n",
      "21763/21763 - 9s - loss: 0.3508 - 9s/epoch - 403us/step\n",
      "Epoch 4/10\n",
      "21763/21763 - 8s - loss: 0.3508 - 8s/epoch - 374us/step\n",
      "Epoch 5/10\n",
      "21763/21763 - 8s - loss: 0.3517 - 8s/epoch - 374us/step\n",
      "Epoch 6/10\n",
      "21763/21763 - 8s - loss: 0.3506 - 8s/epoch - 373us/step\n",
      "Epoch 7/10\n",
      "21763/21763 - 8s - loss: 0.3509 - 8s/epoch - 383us/step\n",
      "Epoch 8/10\n",
      "21763/21763 - 8s - loss: 0.3512 - 8s/epoch - 372us/step\n",
      "Epoch 9/10\n",
      "21763/21763 - 8s - loss: 0.3508 - 8s/epoch - 378us/step\n",
      "Epoch 10/10\n",
      "21763/21763 - 8s - loss: 0.3508 - 8s/epoch - 383us/step\n",
      "Fitted the model 10 with 211 params!\n",
      "21763/21763 [==============================] - 6s 279us/step\n",
      "2721/2721 [==============================] - 1s 308us/step\n",
      "Epoch 1/10\n",
      "21763/21763 - 9s - loss: 0.3491 - 9s/epoch - 394us/step\n",
      "Epoch 2/10\n",
      "21763/21763 - 9s - loss: 0.3527 - 9s/epoch - 399us/step\n",
      "Epoch 3/10\n",
      "21763/21763 - 9s - loss: 0.3551 - 9s/epoch - 398us/step\n",
      "Epoch 4/10\n",
      "21763/21763 - 9s - loss: 0.3539 - 9s/epoch - 406us/step\n",
      "Epoch 5/10\n",
      "21763/21763 - 8s - loss: 0.3534 - 8s/epoch - 390us/step\n",
      "Epoch 6/10\n",
      "21763/21763 - 9s - loss: 0.3497 - 9s/epoch - 396us/step\n",
      "Epoch 7/10\n",
      "21763/21763 - 10s - loss: 0.3499 - 10s/epoch - 439us/step\n",
      "Epoch 8/10\n",
      "21763/21763 - 9s - loss: 0.3499 - 9s/epoch - 396us/step\n",
      "Epoch 9/10\n",
      "21763/21763 - 9s - loss: 0.3504 - 9s/epoch - 416us/step\n",
      "Epoch 10/10\n",
      "21763/21763 - 10s - loss: 0.3495 - 10s/epoch - 451us/step\n",
      "Fitted the model 16_5 with 411 params!\n",
      "21763/21763 [==============================] - 6s 288us/step\n",
      "2721/2721 [==============================] - 1s 305us/step\n",
      "Epoch 1/10\n",
      "21763/21763 - 10s - loss: 0.4556 - 10s/epoch - 451us/step\n",
      "Epoch 2/10\n",
      "21763/21763 - 10s - loss: 0.4598 - 10s/epoch - 440us/step\n",
      "Epoch 3/10\n",
      "21763/21763 - 10s - loss: 0.4597 - 10s/epoch - 444us/step\n",
      "Epoch 4/10\n",
      "21763/21763 - 10s - loss: 0.4598 - 10s/epoch - 443us/step\n",
      "Epoch 5/10\n",
      "21763/21763 - 9s - loss: 0.4598 - 9s/epoch - 436us/step\n",
      "Epoch 6/10\n",
      "21763/21763 - 9s - loss: 0.4598 - 9s/epoch - 434us/step\n",
      "Epoch 7/10\n",
      "21763/21763 - 10s - loss: 0.4598 - 10s/epoch - 438us/step\n",
      "Epoch 8/10\n",
      "21763/21763 - 10s - loss: 0.4599 - 10s/epoch - 438us/step\n",
      "Epoch 9/10\n",
      "21763/21763 - 10s - loss: 0.4597 - 10s/epoch - 452us/step\n",
      "Epoch 10/10\n",
      "21763/21763 - 9s - loss: 0.4598 - 9s/epoch - 434us/step\n",
      "Fitted the model 32_10_20 with 1211 params!\n",
      "21763/21763 [==============================] - 7s 332us/step\n",
      "2721/2721 [==============================] - 1s 293us/step\n",
      "Epoch 1/10\n",
      "21763/21763 - 11s - loss: 0.4543 - 11s/epoch - 517us/step\n",
      "Epoch 2/10\n",
      "21763/21763 - 12s - loss: 0.4598 - 12s/epoch - 530us/step\n",
      "Epoch 3/10\n",
      "21763/21763 - 11s - loss: 0.4599 - 11s/epoch - 510us/step\n",
      "Epoch 4/10\n",
      "21763/21763 - 11s - loss: 0.4599 - 11s/epoch - 506us/step\n",
      "Epoch 5/10\n",
      "21763/21763 - 10s - loss: 0.4599 - 10s/epoch - 466us/step\n",
      "Epoch 6/10\n",
      "21763/21763 - 10s - loss: 0.4598 - 10s/epoch - 466us/step\n",
      "Epoch 7/10\n",
      "21763/21763 - 11s - loss: 0.4599 - 11s/epoch - 483us/step\n",
      "Epoch 8/10\n",
      "21763/21763 - 10s - loss: 0.4599 - 10s/epoch - 479us/step\n",
      "Epoch 9/10\n",
      "21763/21763 - 10s - loss: 0.4598 - 10s/epoch - 478us/step\n",
      "Epoch 10/10\n",
      "21763/21763 - 11s - loss: 0.4599 - 11s/epoch - 522us/step\n",
      "Fitted the model 10_20_30_10 with 1371 params!\n",
      "21763/21763 [==============================] - 7s 341us/step\n",
      "2721/2721 [==============================] - 1s 300us/step\n",
      "Epoch 1/10\n",
      "21763/21763 - 15s - loss: 0.4598 - 15s/epoch - 688us/step\n",
      "Epoch 2/10\n",
      "21763/21763 - 14s - loss: 0.4598 - 14s/epoch - 625us/step\n",
      "Epoch 3/10\n",
      "21763/21763 - 14s - loss: 0.4597 - 14s/epoch - 660us/step\n",
      "Epoch 4/10\n",
      "21763/21763 - 14s - loss: 0.4599 - 14s/epoch - 625us/step\n",
      "Epoch 5/10\n",
      "21763/21763 - 14s - loss: 0.4598 - 14s/epoch - 647us/step\n",
      "Epoch 6/10\n",
      "21763/21763 - 14s - loss: 0.4598 - 14s/epoch - 623us/step\n",
      "Epoch 7/10\n",
      "21763/21763 - 14s - loss: 0.4599 - 14s/epoch - 623us/step\n",
      "Epoch 8/10\n",
      "21763/21763 - 14s - loss: 0.4598 - 14s/epoch - 659us/step\n",
      "Epoch 9/10\n",
      "21763/21763 - 14s - loss: 0.4598 - 14s/epoch - 642us/step\n",
      "Epoch 10/10\n",
      "21763/21763 - 14s - loss: 0.4598 - 14s/epoch - 630us/step\n",
      "Fitted the model 128_64_32_64_16_4 with 16121 params!\n",
      "21763/21763 [==============================] - 7s 338us/step\n",
      "2721/2721 [==============================] - 1s 342us/step\n",
      "Epoch 1/10\n",
      "21763/21763 - 63s - loss: 3.4075 - 63s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "21763/21763 - 71s - loss: 0.4598 - 71s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "21763/21763 - 87s - loss: 0.4598 - 87s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "21763/21763 - 91s - loss: 0.4598 - 91s/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "21763/21763 - 79s - loss: 0.4598 - 79s/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "21763/21763 - 67s - loss: 0.4598 - 67s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "21763/21763 - 63s - loss: 0.4598 - 63s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "21763/21763 - 64s - loss: 0.4599 - 64s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "21763/21763 - 68s - loss: 0.4598 - 68s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "21763/21763 - 72s - loss: 0.4598 - 72s/epoch - 3ms/step\n",
      "Fitted the model 16_64_256_1024_512_128_32_4 with 875945 params!\n",
      "21763/21763 [==============================] - 26s 1ms/step\n",
      "2721/2721 [==============================] - 3s 945us/step\n",
      "Epoch 1/10\n",
      "21763/21763 - 24s - loss: 0.9871 - 24s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "21763/21763 - 23s - loss: 0.4599 - 23s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "21763/21763 - 23s - loss: 0.4598 - 23s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "21763/21763 - 23s - loss: 0.4598 - 23s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "21763/21763 - 23s - loss: 0.4598 - 23s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "21763/21763 - 23s - loss: 0.4599 - 23s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "21763/21763 - 23s - loss: 0.4598 - 23s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "21763/21763 - 23s - loss: 0.4598 - 23s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "21763/21763 - 23s - loss: 0.4599 - 23s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "21763/21763 - 23s - loss: 0.4598 - 23s/epoch - 1ms/step\n",
      "Fitted the model 190_153_120_91_66_45_28_15_6 with 73427 params!\n",
      "21763/21763 [==============================] - 9s 426us/step\n",
      "2721/2721 [==============================] - 1s 413us/step\n",
      "RESULTS:\n",
      "Model 10: Training Accuracy: 0.54, CV Accuracy: 0.53\n",
      "Model 16_5: Training Accuracy: 0.58, CV Accuracy: 0.58\n",
      "Model 32_10_20: Training Accuracy: 0.00, CV Accuracy: 0.00\n",
      "Model 10_20_30_10: Training Accuracy: 0.00, CV Accuracy: 0.00\n",
      "Model 128_64_32_64_16_4: Training Accuracy: 0.00, CV Accuracy: 0.00\n",
      "Model 16_64_256_1024_512_128_32_4: Training Accuracy: 0.00, CV Accuracy: 0.00\n",
      "Model 190_153_120_91_66_45_28_15_6: Training Accuracy: 0.00, CV Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "f1s = {\n",
    "    \"train\": [],\n",
    "    \"cv\": []\n",
    "}\n",
    "\n",
    "for model in models:\n",
    "    # Setup the loss and optimizer\n",
    "    model.compile(\n",
    "        loss='BinaryCrossentropy',\n",
    "    \n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.1),\n",
    "    )\n",
    "    # Train the model\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=10,\n",
    "        verbose=2\n",
    "    )\n",
    "    print(f\"Fitted the model {model.name} with {model.count_params()} params!\")\n",
    "    \n",
    "    # Record the training MSEs\n",
    "    yhat = (model.predict(X_train_scaled) > 0.5).astype(int)\n",
    "    train_f1 = f1_score(y_train, yhat)\n",
    "    f1s['train'].append(train_f1)\n",
    "    \n",
    "    # Record the cross validation MSEs \n",
    "    yhat = (model.predict(X_cv_scaled) > 0.5).astype(int)\n",
    "    cv_ms = f1_score(y_cv, yhat)\n",
    "    f1s['cv'].append(cv_ms)\n",
    "\n",
    "# print results\n",
    "print(\"RESULTS:\")\n",
    "for model_num in range(len(f1s['cv'])):\n",
    "    print(\n",
    "        f\"Model {models[model_num].name}: Training Accuracy: {f1s['train'][model_num]:.2f}, \" +\n",
    "        f\"CV Accuracy: {f1s['cv'][model_num]:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
